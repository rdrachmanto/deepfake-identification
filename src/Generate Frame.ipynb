{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49e2f0d3-a293-44be-8a0c-0bc31dbee7f3",
   "metadata": {},
   "source": [
    "## Generate Frames\n",
    "\n",
    "Generate cropped face images from video input, currently the video inputs are stored in `samples/`. The video is split into frames and passed into face detector: `dlib` or `facenet-pytorch.mtcnn`. The resulting images are stored in `genframes`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e984188-5611-42bb-ad0b-29f34e98eaed",
   "metadata": {},
   "source": [
    "### Modules\n",
    "\n",
    "Below are modules required to run this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6caef6-f1c4-4db8-b6fa-420ef624b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core modules\n",
    "from pathlib import Path\n",
    "\n",
    "# Computer vision-related\n",
    "import cv2\n",
    "import dlib\n",
    "import facenet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cacaf3-d4f2-4819-9265-223781ff902f",
   "metadata": {},
   "source": [
    "### Face Detection with Dlib\n",
    "\n",
    "First, the path for the generated frames are specified, and the directories are created if it doesn't exist yet. Then the process of splitting to frame, detecting the face and saving the faces began."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443b1a3b-68a1-4ec0-a528-66dc23625c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fr_path = \"./genframes\"\n",
    "Path(gen_fr_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f7029-bd75-4635-8ecd-fd21dc66891b",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Capture the video through `cv2` and splits them to frames.\n",
    "2. Apply grayscale to each frame with `cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)`\n",
    "3. Insert the grayed frames to the face detector.\n",
    "4. If face is detected, then the bounding box details are retrieved\n",
    "5. From the retrieved bounding box information, new \"smaller\" face frames are created and saved to `genframes/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847d1567-6898-42ef-8368-21be45b8209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    capture = cv2.VideoCapture(f\"./samples/id0_000{i}.mp4\")\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        if frame_count == 10:\n",
    "            break\n",
    "\n",
    "        _, frame = capture.read()\n",
    "        greyed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "        faces = detector(frame, 1)\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            x, y, w, h = (\n",
    "                faces[0].left(),\n",
    "                faces[0].top(),\n",
    "                faces[0].width(),\n",
    "                faces[0].height()\n",
    "            )\n",
    "\n",
    "            cropped_head = frame[y:y+h, x:x+w]\n",
    "            cv2.imwrite(\n",
    "                f\"./genframes/id0_000{i}_frame_{frame_count}.jpg\",\n",
    "                cropped_head\n",
    "            )\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    capture.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
