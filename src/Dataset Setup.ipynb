{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fd31f5-adf3-402c-9e82-69f19ea92b5f",
   "metadata": {},
   "source": [
    "## Dataset Setup\n",
    "\n",
    "This document will set up the three datasets used in this work: `DFDC`, `FaceForensics++`, and `Celeb-DF-v2`. After the completion of downloading the datasets, each are restructured to follow the `FAKE`, and `REAL` labeling. \n",
    "\n",
    "Raw dataset must be placed in `datasets/raws/` directory. We are going to select 400 videos for each class for the individual dataset, and have 600 videos for each in the combined dataset.\n",
    "\n",
    "| Dataset         | Real | Fake | Total |\n",
    "|-----------------|------|------|-------|\n",
    "| DFDC            | 400  | 400  | 800   |\n",
    "| FaceForensics++ | 400  | 400  | 800   |\n",
    "| Celeb-DF-v2     | 400  | 400  | 800   |\n",
    "| Combined        | 600  | 600  | 1200  |\n",
    "\n",
    "Videos filtered from this will be available in `datasets/filtered/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ef47d8-4900-4a6e-92b2-081e67fcd6d4",
   "metadata": {},
   "source": [
    "### Downloading the Datasets\n",
    "\n",
    "`DFDC` and `Celeb-DF-v2` can be downloaded from these respective links for each datasets:\n",
    "- [DFDC](https://www.kaggle.com/c/deepfake-detection-challenge/data)  \n",
    "- [Celeb-DF-v2](https://drive.google.com/open?id=1iLx76wsbi9itnkxSqz9BVBl4ZvnbIazj)\n",
    "\n",
    "For `FaceForensics++`, a specialized script is used. The specialized script is called like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dcbc9a-9d92-414b-ad97-45dd620b4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate again if needed\n",
    "# !python helper/ff_downloader.py datasets/raws/FaceForensics -d Deepfakes -c raw -t videos -n 100 --server EU2\n",
    "# !python helper/ff_downloader.py datasets/raws/FaceForensics -d Face2Face -c raw -t videos -n 100 --server EU2\n",
    "# !python helper/ff_downloader.py datasets/raws/FaceForensics -d FaceSwap -c raw -t videos -n 100 --server EU2\n",
    "# !python helper/ff_downloader.py datasets/raws/FaceForensics -d NeuralTextures -c raw -t videos -n 100 --server EU2\n",
    "# !python helper/ff_downloader.py datasets/raws/FaceForensics -d original -c raw -t videos -n 400 --server EU2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e48cea-087b-4673-b4d4-8af8e7c787b3",
   "metadata": {},
   "source": [
    "### Split Each Dataset to REAL/FAKE\n",
    "\n",
    "Reorganizing `Celeb-DF-v2` and `FaceForensics` can be solved by simply modifying the directory structure, whereas `DFDC` requires a bit more work as we need to determine each image's label through another file, `metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f98e902-306d-4b79-bbb2-e0bd79d660da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "\n",
    "def organize_to_filtered(dataset, new_fd, dir_map, max=400):\n",
    "    print(\"\")\n",
    "    for dmap in dir_map:\n",
    "        raw_loc = f\"{dataset}/{dmap}\"\n",
    "        new_loc = f\"{new_fd}/{dir_map[dmap]}\"\n",
    "\n",
    "        if not os.path.exists(new_loc):\n",
    "            os.makedirs(new_loc)\n",
    "\n",
    "        # TODO: \"./raws/FaceForensics\" should not be hardcoded for flexibility\n",
    "        ff_cat = dmap.split(\"/\")[-3] if dataset == \"./raws/FaceForensics\" else \"\"\n",
    "\n",
    "        for i, file in enumerate(os.listdir(raw_loc)):\n",
    "            tf_file = f\"{new_loc}/{dmap}_{file}\" if ff_cat == \"\" else f\"{new_loc}/{ff_cat}_{file}\"\n",
    "            if i < max:\n",
    "                shutil.copy(f\"{raw_loc}/{file}\", tf_file)\n",
    "\n",
    "        print(f\"Moved {raw_loc} to {new_loc}\")\n",
    "\n",
    "\n",
    "def organize_mul_from_metadata(datasets, new_fd, metadatas, max=400):\n",
    "    counter = {\n",
    "        \"REAL\": 0,\n",
    "        \"FAKE\": 0,\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(new_fd):\n",
    "        os.makedirs(f\"{new_fd}/FAKE\")\n",
    "        os.makedirs(f\"{new_fd}/REAL\")\n",
    "\n",
    "    for ids, ds in enumerate(datasets):\n",
    "        with open(metadatas[ids], \"r\") as metafile:\n",
    "            json_data = json.load(metafile)\n",
    "            for i, file in enumerate(os.listdir(ds)):\n",
    "                if file == \"metadata.json\":\n",
    "                    continue\n",
    "\n",
    "                label = json_data[file]['label']\n",
    "                if counter[label] < max:\n",
    "                    shutil.copy(f\"{ds}/{file}\", f\"{new_fd}/{label}/{file}\")\n",
    "                    counter[label] += 1\n",
    "\n",
    "                if counter[\"REAL\"] == max and counter[\"FAKE\"] == max:\n",
    "                    print(\"\\nAll labels are maxed!\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa4cb3a0-4f82-4853-8296-da25b3c39b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Activate again if needed\n",
    "# organize_to_filtered(\"./raws/Celeb-DF-v2\", \"./videos-organized/Celeb-DF-v2\", {\n",
    "#     \"Celeb-real\": \"REAL\",\n",
    "#     \"Celeb-synthesis\": \"FAKE\"\n",
    "# })\n",
    "\n",
    "# organize_to_filtered(\n",
    "#     \"./raws/FaceForensics\",\n",
    "#     \"./videos-organized/FaceForensics\",\n",
    "#     {\n",
    "#         \"original_sequences/youtube/raw/videos\": \"REAL\",\n",
    "#         \"manipulated_sequences/Deepfakes/raw/videos\": \"FAKE\",\n",
    "#         \"manipulated_sequences/Face2Face/raw/videos\": \"FAKE\",\n",
    "#         \"manipulated_sequences/FaceSwap/raw/videos\": \"FAKE\",\n",
    "#         \"manipulated_sequences/NeuralTextures/raw/videos\": \"FAKE\",\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# dfdc_datasets = [\n",
    "#     \"./raws/dfdc_train_part_0\",\n",
    "#     \"./raws/dfdc_train_part_1\",\n",
    "#     \"./raws/dfdc_train_part_2\",\n",
    "#     \"./raws/dfdc_train_part_3\",\n",
    "#     \"./raws/dfdc_train_part_4\"\n",
    "# ]\n",
    "\n",
    "# dfdc_metadatas = [\n",
    "#     \"./raws/dfdc_train_part_0/metadata.json\",\n",
    "#     \"./raws/dfdc_train_part_1/metadata.json\",\n",
    "#     \"./raws/dfdc_train_part_2/metadata.json\",\n",
    "#     \"./raws/dfdc_train_part_3/metadata.json\",\n",
    "#     \"./raws/dfdc_train_part_4/metadata.json\"\n",
    "# ]\n",
    "\n",
    "# organize_mul_from_metadata(dfdc_datasets, \"./videos-organized/DFDC\", dfdc_metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14610bdc-87c0-49a0-8937-d20f4918673e",
   "metadata": {},
   "source": [
    "### Create Combined Dataset\n",
    "\n",
    "With the datasets now organized, it is easier to create the combined set. For now, the combined set will take the first 200 videos from each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4e030f8-88a1-475f-bf68-29fdcf9e4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_ds(datasets, classes, combined_ds_path, max_per_class=200):\n",
    "    if not os.path.exists(combined_ds_path):\n",
    "        for c in classes:\n",
    "            os.makedirs(f\"{combined_ds_path}/{c}\")\n",
    "\n",
    "    for ds in datasets:\n",
    "        for cl in classes:\n",
    "            for i, file in enumerate(os.listdir(f\"{ds}/{cl}\")):\n",
    "                if i == max_per_class:\n",
    "                    print(f\"Finish inserting {ds}-{cl}\")\n",
    "                    break\n",
    "\n",
    "                shutil.copy(f\"{ds}/{cl}/{file}\", f\"{combined_ds_path}/{cl}/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f50fb4e7-c070-4bf8-8042-472f2911d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish inserting ./videos-organized/Celeb-DF-v2-REAL\n",
      "Finish inserting ./videos-organized/Celeb-DF-v2-FAKE\n",
      "Finish inserting ./videos-organized/DFDC-REAL\n",
      "Finish inserting ./videos-organized/DFDC-FAKE\n",
      "Finish inserting ./videos-organized/FaceForensics-REAL\n",
      "Finish inserting ./videos-organized/FaceForensics-FAKE\n"
     ]
    }
   ],
   "source": [
    "organized_ds = [\n",
    "    \"./videos-organized/Celeb-DF-v2\",\n",
    "    \"./videos-organized/DFDC\",\n",
    "    \"./videos-organized/FaceForensics\"\n",
    "]\n",
    "\n",
    "classes = [\"REAL\", \"FAKE\"]\n",
    "\n",
    "create_combined_ds(organized_ds, classes, \"./videos-organized/Combined\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
