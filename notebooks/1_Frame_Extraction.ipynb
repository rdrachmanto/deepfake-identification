{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39bc9f71-1368-413c-8e83-49cc2927cee5",
   "metadata": {},
   "source": [
    "## Frame Extraction\n",
    "\n",
    "Below are example codes for preprocessing a raw dataset of videos into face frames, with `facenet_pytorch.MTCNN`. Make sure that the raw dataset has its directory structured like the one mentioned in the [README.md](../README.md).\n",
    "\n",
    "**Please be aware:** you might need to do more than one run of frame extraction due to possible face detection failures from `MTCNN`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66808b9-fe8f-4e1f-bb6f-65b31b396977",
   "metadata": {},
   "source": [
    "### Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7654d68-b09d-4b06-9155-f666a0b8c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure __init__.py is being run before the script\n",
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943cca68-f34d-4774-899b-39fe1dd2771b",
   "metadata": {},
   "source": [
    "### Extraction\n",
    "\n",
    "There are two sampling-based generators: `MTCNNSampleExtractor` and `MTCNNSeqExtractor`. Both have similar APIs. To instantiate these extractor classes, provide two arguments:\n",
    "\n",
    "- `dataset_path (str)`: Relative path to the raw dataset\n",
    "- `classes (list[str])`: Folders inside the dataset\n",
    "\n",
    "After instantiating, you can call `extract()` function to begin the frame extraction. Arguments for `extract()` are:\n",
    "\n",
    "- `save_to (str)`: Where to save the extracted images\n",
    "- `n_frame (int)`: How many frames to extract per video\n",
    "- `cut_amount (float)`: Percentage of frames to be cut. e.g. setting to 0.1 is equal to 10% frames being cut in front and back, totaling 20%.\n",
    "- `batch_size (int)`: How many videos to process in a batch\n",
    "- `seed (int)`: (Only for SampleExtractor) To control the randomizer, guaranteeing identical reproducible results at every run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d481b9a-9605-43a7-9ac0-bb0a9dda3073",
   "metadata": {},
   "source": [
    "#### Sampling Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9689803-3371-4dad-b357-e4268561d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from src.preprocessing.extractors.mtcnn_extractors import MTCNNSampleExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b605ca58-8b58-488d-8c8b-2470950027df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting Celeb-DF-v2's samples for 1133.86s!\n",
      "Done extracting DFDC's samples for 5033.5s!\n",
      "Done extracting FaceForensics's samples for 7180.26s!\n",
      "Done extracting Combined's samples for 6619.11s!\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    \"Celeb-DF-v2\",\n",
    "    \"DFDC\",\n",
    "    \"FaceForensics\",\n",
    "    \"Combined\"\n",
    "]\n",
    "\n",
    "for d in datasets:\n",
    "    ext = MTCNNSampleExtractor(\n",
    "        dataset_path=f\"../data/raw/{d}\",\n",
    "        classes=[\"REAL\", \"FAKE\"]\n",
    "    )\n",
    "\n",
    "    start = datetime.now()\n",
    "    ext.extract(\n",
    "        save_to=f\"../data/preprocessed/MTCNN-{d}\",\n",
    "        n_frame=10,\n",
    "        cut_amount=0.15,\n",
    "        batch_size=10,\n",
    "        seed=42,\n",
    "    )\n",
    "    elapsed = round((datetime.now() - start).total_seconds(), 2)\n",
    "    print(f\"Done extracting {d}'s samples for {elapsed}s!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01279c9a-d9b9-4044-88ec-2e48ae175ff3",
   "metadata": {},
   "source": [
    "#### Sequential \n",
    "\n",
    "As explained earlier, `MTCNN` might fail. If there is only six out of ten frames required in a video, we need to get the remaining four. We can either redo the sampling process to involve another seed, or to speed up the process, we can do it sequentially (looping over all the available frames and detect faces). That is what we are going to do here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9508337-9448-47e2-8011-b541ded6442b",
   "metadata": {},
   "source": [
    "##### Gatherer\n",
    "\n",
    "With this we match the target directory (directory from sampling-based) with the source directory (raw data). if a video is found to have its number of frames less than `need_to_match`, then it is part of the \"incomplete\" data. This incomplete data is in the form of a dictionary.\n",
    "\n",
    "This dictionary is shaped like so:\n",
    "\n",
    "```python\n",
    "    # filename: incomplete frames count\n",
    "    {\n",
    "     \"../data/raw/DFDC/aaxejguth.mp4\": 2,\n",
    "     \"../data/raw/DFDC/mniodsvhr.mp4\": 6,\n",
    "    }\n",
    "```\n",
    "\n",
    "This dictionary will be passed onto a sequence-based extractor, to redo the face detection, and solve the incompleteness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4e04529-067f-4f34-b1fc-44e8aaa4f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33132b3a-3abb-4bad-8b09-110dfeab5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "def count_for_match(source, target, need_to_match):\n",
    "    src_files = os.listdir(source)\n",
    "    target_files = os.listdir(target)\n",
    "\n",
    "    eligibles = {}\n",
    "    for srcf in src_files:\n",
    "        r = re.compile(rf\".*{srcf}\")\n",
    "        trgf = list(filter(r.match, target_files))\n",
    "        if len(trgf) < need_to_match:\n",
    "            eligibles[f\"{source}/{srcf}\"] = need_to_match - len(trgf)\n",
    "    return eligibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c8247-4629-4d21-93a0-04104dd9bcfc",
   "metadata": {},
   "source": [
    "##### Sequential Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55a3b72-0265-4e71-94e0-236a92cfad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "from src.preprocessing.extractors.mtcnn_extractors import MTCNNSeqExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed98d746-1139-455c-8aac-8e13a547792f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done extracting Celeb-DF-v2's samples for 1.59s!\n",
      "Done extracting DFDC's samples for 164.33s!\n",
      "Done extracting FaceForensics's samples for 1.15s!\n",
      "Done extracting Combined's samples for 81.96s!\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    \"Celeb-DF-v2\",\n",
    "    \"DFDC\",\n",
    "    \"FaceForensics\",\n",
    "    \"Combined\"\n",
    "]\n",
    "preprocessor = \"MTCNN\"\n",
    "classes = [\"REAL\", \"FAKE\"]\n",
    "\n",
    "for d in datasets:\n",
    "    start = datetime.now()\n",
    "    for c in classes:\n",
    "        x = count_for_match(\n",
    "            f\"../data/raw/{d}/{c}\", \n",
    "            f\"../data/preprocessed/{preprocessor}-{d}/{c}\",\n",
    "            10\n",
    "        )\n",
    "\n",
    "        if not len(list(x)) > 0:\n",
    "            continue\n",
    "\n",
    "        p = MTCNNSeqExtractor(x)\n",
    "        p.extract(save_to=f\"../data/preprocessed/{preprocessor}-{d}\", cut_amount=0.15)\n",
    "    elapsed = round((datetime.now() - start).total_seconds(), 2)\n",
    "    print(f\"Done extracting {d}'s samples for {elapsed}s!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
